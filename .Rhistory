1+1
quit()
# The linkedin vector has already been defined for you
linkedin <- c(16, 9, 13, 5, 2, 17, 14)
# Code the for loop with conditionals
for (i in 1:length(linkedin)) {
if (linkedin[i] > 10) {
print("Your're popular!")
} else {
print("Be more visible!")
}
print(linkedin[i])
}
rquote <- "R's internals are irrefutably intriguing"
chars <- strsplit(rquote, split = "")[[1]]
rquote
chars
?strsplit
chars <- strsplit(rquote, split = "")
chars
chars <- strsplit(rquote, split = "")[[1]]
rquote <- "R's internals are irrefutably intriguing"
chars <- strsplit(rquote, split = "")[[1]]
for (i in 1:length(chars)) {
print(i)
}
rquote <- "R's internals are irrefutably intriguing"
chars <- strsplit(rquote, split = "")[[1]]
rcount <- 0
for (i in 1:length(chars)) {
if (chars[i]=="r" | chars[i]=="R") { rcount <- rcount + 1}
if (chars[i]=="u") {break}
}
print(rcount)
p <- c(1,2,3,4,NA,5,6,7)
p <- c(1,2,3,4,na,5,6,7)
sd(p)
sd(p)
sd(p, na.rm = TRUE)
p1 <- c(1,2,3,4,5,6,7)
p2 <- c(1,2,3,4,NA,5,6,7)
sd(p1)
args(sd)
args(sample)
?mean
linkedin <- c(16, 9, 13, 5, 2, 17, 14)
facebook <- c(17, 7, 5, 16, 8, 13, 14)
sum(linkedin)
sum(facebook)
avg_sum <- c(sum(linkedin), sum(facebook))
avg_sum <- mean(c(sum(linkedin), sum(facebook)))
avg_sum <- mean(linkedin + facebook)
linkedin + facebook
t <- c(1,2,3,4,5,6,7,8,9,10)
mean(t)
t <- c(1,2,3,4,5,6,7,8,9)
mean(t)
mean(t, trim = 0.5)
t <- c(1,2,3,4,5,6,7,8,11)
mean(t)
mean(t, trim = 0.5)
mean(t, trim = 0.4)
mean(t, trim = 0.3)
mean(t, trim = 0.2)
mean(t, trim = 0.1)
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
sim <- rpois(n*rows, lambda)
m <- matrix(sim, rows)
# m <- matrix(rpois(n*rows, lambda), rows)
sample.means <- rowMeans(m)
?png
png(filename="sample-means.png"); hist(sample.means)
png(filename="sample-means.png"); hist(sample.means)
hist(sample.means)
sample.means
?hist
hist(sample.means)
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
sim <- rpois(n*rows, lambda)
m <- matrix(sim, rows)
# m <- matrix(rpois(n*rows, lambda), rows)
sample.means <- rowMeans(m)
# sample.means <- apply(m, 1, mean)
sm.avg <- mean(sample.means); sm.sd <- sd(sample.means)
sm.sd.clt <- sqrt(lambda/n)
?hist
hist(sample.means, 10)
head(m)
tail(m)
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
sim <- rpois(n*rows, lambda)
m <- matrix(sim, rows)
# m <- matrix(rpois(n*rows, lambda), rows)
sample.means <- rowMeans(m)
# sample.means <- apply(m, 1, mean)
sm.avg <- mean(sample.means); sm.sd <- sd(sample.means)
sm.sd.clt <- sqrt(lambda/n)
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
sim <- rpois(n*rows, lambda)
m <- matrix(sim, rows)
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
sim <- rpois(n*rows, lambda)
m <- matrix(sim, rows)
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
sim <- rpois(n*rows, lambda)
m <- matrix(sim, rows)
set.seed(47)
lambda <- 5 # For Poisson distribution
n <- 40; rows <- 1000 # 1,000 trials, sample size = 40 each
sim <- rpois(n*rows, lambda)
m <- matrix(sim, rows)
sample.means <- rowMeans(m)
sm.avg <- mean(sample.means); sm.sd <- sd(sample.means)
sm.sd.clt <- sqrt(lambda/n)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(caret); library(kernlab); data(spam)
install.packages("kernlab")
library(caret); library(kernlab); data(spam)
p=0.75, list=FALSE)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
View(inTrain)
?createDataPartition
View(inTrain)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
View(testing)
View(inTrain)
dim(training)
data(AlzheimerDisease)
?data
?data.frame
y <- AlzheimerDisease
?AlzheimerDisease
??AlzheimerDisease
data(AlzheimerDisease)
str(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
diagnosis
str(diagnosis)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
View(inTrain)
training <- spam[inTrain,]
adData = data.frame(diagnosis,predictors)
View(adData)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(training)
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
library(ISLR); library(ggplot2); library(caret);
install.packages("ISLR")
library(ISLR); library(ggplot2); library(caret);
library(ISLR); library(ggplot2); library(caret);
data(Wage)
summary(Wage)
featurePlot(x=training[,c("age","education","jobclass")], y = training$wage, plot="pairs")
library(ISLR); library(ggplot2); library(caret);
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
str(inTrain)
?createDataPartition
head(inTrain)
inTrain
str(inTrain)
Wage
Wage$wage
str(inTrain)
wage[1]
Wage[1]
whatsthis <- Wage[1]
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")], y = training$wage, plot="pairs")
data(iris); library(ggplot2)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
data(iris); library(ggplot2)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
table(iris$Species)
qplot(Petal.Length,Sepal.Width,colour=Species,data=training)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
data(iris); library(ggplot2)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
training <- iris[inTrain,]
data(iris); library(ggplot2)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
data(iris); library(ggplot2); library(caret)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Length,Sepal.Width,colour=Species,data=training)
modFit <- train(Species ~ .,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rattle)
library(rattle)
install.packages("rattle")
library(rattle)
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
data(iris); library(ggplot2); library(caret)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Length,Sepal.Width,colour=Species,data=training)
modFit <- train(Species ~ .,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
rattle()
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
data(iris); library(ggplot2); library(caret)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Length,Sepal.Width,colour=Species,data=training)
modFit <- train(Species ~ .,method="rpart",data=training)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
search()
fancyRpartPlot(modFit$finalModel)
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
install.packages("ElemStatLearn")
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA,nrow=10,ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit
getTree(modFit$finalModel, k=2)
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col=Species,data=training)
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
pred <- predict(modFit,testing); testing$predRight <- pred==testing$Species
table(pred,testing$Species)
qplot(Petal.Width,Petal.Length,colour=predRight,data=testing,main="newdata Predictions")
library(ISLR); data(Wage); library(ggplot2); library(caret);
Wage <- subset(Wage,select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
modFit <- train(wage ~ ., method="gbm",data=training,verbose=FALSE)
library(ISLR); data(Wage); library(ggplot2); library(caret)
Wage <- subset(Wage,select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
modFit <- train(wage ~ ., method="gbm",data=training,verbose=FALSE)
print(modFit)
qplot(predict(modFit,testing),wage,data=testing)
warnings()
data(iris); library(ggplot2)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
modlda = train(Species ~ .,data=training,method="lda")
modnb = train(Species ~ ., data=training,method="nb")
install.packages("lkar")
install.packages("klar")
install.packages("klaR")
modlda = train(Species ~ .,data=training,method="lda")
modnb = train(Species ~ ., data=training,method="nb")
plda = predict(modlda,testing); pnb = predict(modnb,testing)
table(plda,pnb)
equalPredictions = (plda==pnb)
qplot(Petal.Width,Sepal.Width,colour=equalPredictions,data=testing)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart); library(ggplot2); library(rattle)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
model<-train(Class ~ .,
data = training,
method = "rpart")
fancyRpartPlot(model$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(model$finalModel)
print(model$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
View(olive)
model <- train(Area ~ ., data = olive, method = "rpart2")
model.rpart <- train(Area ~ ., data = olive, method = "rpart")
model.rparts <- train(Area ~ ., data = olive, method = "rpart2")
model.rpart2 <- train(Area ~ ., data = olive, method = "rpart2")
model.rpart
model.rpart
model.rpart2
model.rpart <- train(Area ~ ., data = olive, method = "rpart")
model.rpart2 <- train(Area ~ ., data = olive, method = "rpart2")
model.rpart
model.rpart2
predict(model.rpart, newdata)
predict(model.rpart2, newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
logit.model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
logit.model
predict.Train <- predict(logit.Model, trainSA)
predict.Test <- predict(logit.Model, testSA)
predict.Train <- predict(logit.model, trainSA)
predict.Test <- predict(logit.Mmdel, testSA)
missClass(trainSA$chd, predict.Train) # 0.2727273
missClass(testSA$chd, predict.Test) # 0.3116883
predict.Test <- predict(logit.Mmdel, testSA)
predict.Test <- predict(logit.model, testSA)
missClass(testSA$chd, predict.Test) # 0.3116883
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
?factor
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
set.seed(33833)
rf.imp <- varImp(rf)
rf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
rf.imp <- varImp(rf)
order(rf)
order(rf.imp)
order(rf.imp, decreasing = T) # [1] 10  7  3  9  4  8  6  5  1  2
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
model.rpart <- train(Area ~ ., data = olive, method = "rpart")
model.rpart2 <- train(Area ~ ., data = olive, method = "rpart2")
model.rpart
model.rpart2
predict(model.rpart, newdata)
predict(model.rpart2, newdata)
?runApp
setwd("D:/GitHub/co-jhds-data-products")
library(shiny)
runExample("01_hello")
run("App-1")
runApp("App-1")
runApp("App-1", display.mode = "showcase")
h1("My title")
runApp("App-1", display.mode = "showcase")
